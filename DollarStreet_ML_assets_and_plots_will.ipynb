{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27345614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U kaleido\n",
    "!pip install plotly\n",
    "!pip install --upgrade torchvision\n",
    "!pip3 install -e dollarstreet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7d5e6",
   "metadata": {},
   "source": [
    "## SETUP: Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2af854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Folder to all copied and generated assets\n",
    "ASSETS_FOLDER = 'experiments/will_2022_10_15'\n",
    "\n",
    "\n",
    "# DATASETS ############################################################\n",
    "\n",
    "# Subfolder to all copied and generated datasets within assets folder\n",
    "DATASETS_FOLDER = 'datasets'\n",
    "\n",
    "# Source files\n",
    "ROOT_DIR = ''\n",
    "IMAGE_FOLDER = 'images_v2'\n",
    "TRAIN_FILE = 'images_v2_imagenet_train_subset_seedcheck.csv'\n",
    "TEST_FILE = 'images_v2_imagenet_test_subset_seedcheck.csv'\n",
    "VALIDATION_FILE = 'images_v2_imagenet_validation_subset_seedcheck.csv'\n",
    "\n",
    "# Quantiles\n",
    "qt_target_col = 'income'\n",
    "qt_col = 'quantile'\n",
    "qts = range(4)\n",
    "\n",
    "# Flag for skipping saving generated datasets (recommend setting to FALSE for just plotting)\n",
    "ALL_SAVE_DATASETS = True\n",
    "QT_SAVE_DATASETS = True\n",
    "\n",
    "\n",
    "# Names of saved files split by quantile\n",
    "QT_TRAIN_FILES = {qt:f'{os.path.splitext(TRAIN_FILE)[0]}_qt{qt}.csv' for qt in qts}\n",
    "QT_VAL_FILES = {qt:f'{os.path.splitext(VALIDATION_FILE)[0]}_qt{qt}.csv' for qt in qts}\n",
    "QT_TEST_FILES = {qt:f'{os.path.splitext(TEST_FILE)[0]}_qt{qt}.csv' for qt in qts}\n",
    "\n",
    "\n",
    "\n",
    "# TRAINING ##############################################################\n",
    "\n",
    "# Subfolder to all copied and generated models within assets folder\n",
    "MODELS_FOLDER = 'models'\n",
    "\n",
    "# Flags for skipping training (recommend setting to FALSE when just plotting)\n",
    "ALL_TRAIN_AND_SAVE_MODELS = True\n",
    "QT_TRAIN_AND_SAVE_MODELS = True\n",
    "\n",
    "\n",
    "# Seeds for training \n",
    "training_seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Number of epochs for training on FULL training set\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "\n",
    "# PLOTS ##############################################################\n",
    "\n",
    "# Subfolder to all copied and generated plots within assets folder\n",
    "PLOTS_FOLDER = 'plots'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5VkiK9Fee",
   "metadata": {
    "id": "a0f5VkiK9Fee"
   },
   "source": [
    "# 1. Generate datasets and models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nwPMffTYOhou",
   "metadata": {
    "id": "nwPMffTYOhou"
   },
   "source": [
    "## 1.1 Create and save train/val/test split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc265b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure save directory exists\n",
    "os.makedirs(os.path.join(\n",
    "    ROOT_DIR, ASSETS_FOLDER, DATASETS_FOLDER), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965c409b",
   "metadata": {},
   "source": [
    "### 1.1.1 For all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Save data in experiment folder\n",
    "for filename in [TRAIN_FILE, VALIDATION_FILE, TEST_FILE]:\n",
    "    df = pd.read_csv(os.path.join(ROOT_DIR, filename))\n",
    "    save_path = os.path.join(\n",
    "        ROOT_DIR, ASSETS_FOLDER, DATASETS_FOLDER, filename)\n",
    "    if ALL_SAVE_DATASETS:\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f'Saved {save_path}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1fc30e",
   "metadata": {},
   "source": [
    "### 1.1.2 For quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ca075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from dollarstreet.datasets import get_csv_dataset\n",
    "from dollarstreet.dataloaders import get_loader\n",
    "\n",
    "\n",
    "# Load relevant dfs\n",
    "train_df = pd.read_csv(os.path.join(ROOT_DIR, TRAIN_FILE))\n",
    "val_df = pd.read_csv(os.path.join(ROOT_DIR, VALIDATION_FILE))\n",
    "test_df = pd.read_csv(os.path.join(ROOT_DIR, TEST_FILE))\n",
    "all_data_df = pd.concat([train_df, val_df, test_df])\n",
    "\n",
    "# Calculate quantile boundaries\n",
    "all_data_quantiles = [\n",
    "    all_data_df[qt_target_col].quantile((i+1)/len(qts)) for i in qts\n",
    "][:len(qts)-1]\n",
    "\n",
    "# Define quantile function using boundaries\n",
    "def get_quantile_from_value(qt_target_col_value: int) -> int:\n",
    "    quantile = 0\n",
    "    for quantile_bound in all_data_quantiles:\n",
    "        if qt_target_col_value <= quantile_bound:\n",
    "            return quantile\n",
    "        quantile += 1\n",
    "    return quantile\n",
    "\n",
    "# Create quantile dfs by split and save in experiment folder\n",
    "split_dfs = {\n",
    "    'train': (train_df, QT_TRAIN_FILES),\n",
    "    'val': (val_df, QT_VAL_FILES), \n",
    "    'test': (test_df, QT_TEST_FILES)\n",
    "}\n",
    "for split in split_dfs.keys():\n",
    "    # Load dataframe and filenames\n",
    "    df, qt_files = split_dfs[split]\n",
    "    \n",
    "    # Split by quantile\n",
    "    df[qt_col] = df[qt_target_col].apply(lambda v: get_quantile_from_value(v))\n",
    "    qt_dfs = {qt: df[df[qt_col] == qt] for qt in qts}\n",
    "\n",
    "    # Print quantile ranges\n",
    "    print(f'{split} set quantiles')\n",
    "    for qt in qts:\n",
    "        print(f'Quantile {qt + 1}/{len(qts)} '\n",
    "              f'min: {qt_dfs[qt][qt_target_col].min()} '\n",
    "              f'max: {qt_dfs[qt][qt_target_col].max()} '\n",
    "              f'mean: {qt_dfs[qt][qt_target_col].mean()} '\n",
    "              f'median: {qt_dfs[qt][qt_target_col].median()} '\n",
    "              f'count: {len(qt_dfs[qt])}')\n",
    "\n",
    "    # Save quantiles\n",
    "    for qt in qts:\n",
    "        save_path = os.path.join(\n",
    "            ROOT_DIR, ASSETS_FOLDER, DATASETS_FOLDER, qt_files[qt])\n",
    "        if QT_SAVE_DATASETS:\n",
    "            qt_dfs[qt].to_csv(save_path, index=False)\n",
    "            print(f'Saved {save_path}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ff7f2",
   "metadata": {},
   "source": [
    "## 1.2 Create dataset and dataloader objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e2320",
   "metadata": {},
   "source": [
    "### 1.2.1 For all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfef9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import dollarstreet.constants as c\n",
    "from dollarstreet.datasets import get_csv_dataset\n",
    "from dollarstreet.dataloaders import get_loader\n",
    "\n",
    "# Datasets\n",
    "split_dfs = {\n",
    "    'train': os.path.join(ROOT_DIR, ASSETS_FOLDER, DATASETS_FOLDER, TRAIN_FILE),\n",
    "    'val': os.path.join(ROOT_DIR, ASSETS_FOLDER, DATASETS_FOLDER, VALIDATION_FILE),\n",
    "    'test': os.path.join(ROOT_DIR, ASSETS_FOLDER, DATASETS_FOLDER, TEST_FILE),\n",
    "}\n",
    "all_datasets = {}\n",
    "for split in split_dfs.keys():\n",
    "    dataset = get_csv_dataset(\n",
    "            csv_file=split_dfs[split],\n",
    "            root_dir=os.path.join(ROOT_DIR, IMAGE_FOLDER),\n",
    "            train= True if split == 'train' else False,\n",
    "            explode=True)\n",
    "    all_datasets[split] = dataset \n",
    "\n",
    "# Loaders\n",
    "all_loaders = {}\n",
    "for split in ['train', 'val', 'test']:\n",
    "    dataset = all_datasets[split]\n",
    "    if split == 'train':\n",
    "        loader = get_loader(dataset)\n",
    "    else:\n",
    "        loader = get_loader(dataset, batch_size=64)\n",
    "    all_loaders[split] = loader\n",
    "        \n",
    "print(all_datasets)\n",
    "print()\n",
    "print(all_loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab8a5f",
   "metadata": {},
   "source": [
    "### 1.2.2 For quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import dollarstreet.constants as c\n",
    "from dollarstreet.datasets import get_csv_dataset\n",
    "from dollarstreet.dataloaders import get_loader\n",
    "\n",
    "\n",
    "# Datasets\n",
    "split_dfs = {\n",
    "    'train': QT_TRAIN_FILES,\n",
    "    'val': QT_VAL_FILES,\n",
    "    'test': QT_TEST_FILES\n",
    "}\n",
    "qt_datasets = {qt: {} for qt in qts}\n",
    "for split in split_dfs.keys():\n",
    "    for qt in qts:\n",
    "        csv_file = os.path.join(\n",
    "            ROOT_DIR, ASSETS_FOLDER, DATASETS_FOLDER, split_dfs[split][qt])\n",
    "        dataset = get_csv_dataset(\n",
    "                csv_file=csv_file,\n",
    "                root_dir=os.path.join(ROOT_DIR, IMAGE_FOLDER),\n",
    "                train= True if split == 'train' else False,\n",
    "                explode=True)\n",
    "        qt_datasets[qt][split] = dataset \n",
    "\n",
    "# Loaders\n",
    "qt_loaders = {qt: {} for qt in qts}\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for qt in qts:\n",
    "        dataset = qt_datasets[qt][split]\n",
    "        if split == 'train':\n",
    "            loader = get_loader(dataset)\n",
    "        else:\n",
    "            loader = get_loader(dataset, batch_size=64)\n",
    "        qt_loaders[qt][split] = loader\n",
    "        \n",
    "print(qt_datasets)\n",
    "print()\n",
    "print(qt_loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e439c9",
   "metadata": {},
   "source": [
    "## 1.3 Train and save FT-resnet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bced49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure save directory exists\n",
    "os.makedirs(os.path.join(\n",
    "    ROOT_DIR, ASSETS_FOLDER, MODELS_FOLDER), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb3d55",
   "metadata": {},
   "source": [
    "### 1.3.1 For all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7367e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from dollarstreet.run import train_models\n",
    "\n",
    "if ALL_TRAIN_AND_SAVE_MODELS:\n",
    "    # Models to fine tune\n",
    "    model_names = [\n",
    "        'resnet',\n",
    "    ]\n",
    "\n",
    "    # Params\n",
    "    train_epochs = NUM_EPOCHS\n",
    "\n",
    "    # Training\n",
    "    all_ftmodel = None\n",
    "    description = (\n",
    "        f'Fine tuning pre-trained {model_names[0]} '\n",
    "        f'model for {train_epochs} epochs on all training data '\n",
    "    )\n",
    "    all_ftmodel, _, _ = train_models(model_names=model_names,\n",
    "                                     dataloaders=all_loaders, \n",
    "                                     num_epochs=train_epochs,\n",
    "                                     seed=training_seeds[0],\n",
    "                                     save_log=True,\n",
    "                                     description=description)\n",
    "\n",
    "    filename = f'{os.path.splitext(TRAIN_FILE)[0]}_ftresnet.pickle'\n",
    "    save_path = os.path.join(\n",
    "        ROOT_DIR, ASSETS_FOLDER, MODELS_FOLDER, filename)\n",
    "    with open(save_path, 'wb') as handle:\n",
    "        pickle.dump(all_ftmodel, handle)\n",
    "    print(f'Fine tuned resnet model saved to {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb2c1b8",
   "metadata": {},
   "source": [
    "### 1.3.2 For quartile training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a73a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from dollarstreet.run import train_models\n",
    "\n",
    "if QT_TRAIN_AND_SAVE_MODELS:\n",
    "    # Models to fine tune\n",
    "    model_names = [\n",
    "        'resnet',\n",
    "    ]\n",
    "\n",
    "    # Params\n",
    "    train_epochs = NUM_EPOCHS * len(qts)\n",
    "\n",
    "    # Training\n",
    "    qt_ftmodels = {}\n",
    "    for qt in qts:\n",
    "        description = (\n",
    "            f'Fine tuning pre-trained {model_names[0]} '\n",
    "            f'model for {train_epochs} epochs on quartile {qt} '\n",
    "            'of training data'\n",
    "        )\n",
    "        qt_ftmodels[qt], _, _ = train_models(model_names=model_names,\n",
    "                                           dataloaders=qt_loaders[qt], \n",
    "                                           num_epochs=train_epochs,\n",
    "                                           seed=training_seeds[0],\n",
    "                                           save_log=True,\n",
    "                                           description=description)\n",
    "\n",
    "        filename = f'{os.path.splitext(QT_TRAIN_FILES[qt])[0]}_ftresnet.pickle'\n",
    "        save_path = os.path.join(\n",
    "            ROOT_DIR, ASSETS_FOLDER, MODELS_FOLDER, filename)\n",
    "        with open(save_path, 'wb') as handle:\n",
    "            pickle.dump(qt_ftmodels[qt], handle)\n",
    "        print(f'Fine tuned resnet model saved to {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b39c6",
   "metadata": {},
   "source": [
    "# 2. Figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa5458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure save directory exists\n",
    "os.makedirs(os.path.join(\n",
    "    ROOT_DIR, ASSETS_FOLDER, PLOTS_FOLDER), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7fd56f",
   "metadata": {},
   "source": [
    "## 2.1 Score pre-trained classifiers on quartile test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0083786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dollarstreet.run import validate_models\n",
    "\n",
    "model_names = [\n",
    "    'resnet',\n",
    "    'squeezenet',\n",
    "    'densenet',\n",
    "    'mobilenet',\n",
    "    'efficientnet',\n",
    "    'shufflenet',\n",
    "    'visionnet',\n",
    "]\n",
    "\n",
    "results_pt = {}\n",
    "for qt in qts:\n",
    "    description = (\n",
    "        f'Scoring all pre-trained models on {qt + 1}/{len(qts)} quantile '\n",
    "        'of test data.'\n",
    "    )\n",
    "    _, top1, top5 = validate_models(model_names=model_names,\n",
    "                                    dataloaders=qt_loaders[qt],\n",
    "                                    seed=training_seeds[0],\n",
    "                                    save_log=False,\n",
    "                                    description=description)\n",
    "    results_pt[qt] = {'top1': top1, 'top5': top5}\n",
    "    print(f'Finished scoring {qt + 1}/{len(qts)} quantile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ceca90",
   "metadata": {},
   "source": [
    "## 2.2 Score FT-resnet on quartile test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b528acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dollarstreet.run import validate_model\n",
    "\n",
    "# Load ft-resnet model\n",
    "filename = f'{os.path.splitext(TRAIN_FILE)[0]}_ftresnet.pickle'\n",
    "model_save_path = os.path.join(\n",
    "        ROOT_DIR, ASSETS_FOLDER, MODELS_FOLDER, filename)\n",
    "\n",
    "with open(model_save_path, 'rb') as handle:\n",
    "    model = pickle.load(handle)['resnet']\n",
    "\n",
    "results_ft = {qt:{} for qt in qts}\n",
    "for qt in qts:\n",
    "    description = (\n",
    "        f'Scoring all fine-tuned model on {qt + 1}/{len(qts)} quantile '\n",
    "        'of test data.'\n",
    "    )\n",
    "    _, top1, top5 = validate_model(model=model,\n",
    "                                   dataloaders=qt_loaders[qt],\n",
    "                                   seed=training_seeds[0],\n",
    "                                   save_log=False,\n",
    "                                   description=description)\n",
    "    results_ft[qt] = {'top1': top1, 'top5': top5}\n",
    "    print(f'Finished scoring {qt + 1}/{len(qts)} quantile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a53703",
   "metadata": {},
   "source": [
    "## 2.3 Plot figure 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73231680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "quartile_labels = ['$27-200', '$200-684', '$685-1,997', '$1,998-19,671']\n",
    "model_labels = [\n",
    "    'squeezenet',\n",
    "    'shufflenet',\n",
    "    'resnet',\n",
    "    'mobilenet',\n",
    "    'densenet',\n",
    "    'efficientnet',\n",
    "    'visionnet',\n",
    "    'fine-tuned resnet',\n",
    "]\n",
    "\n",
    "# Get top 5 accuracy data per model per quartile\n",
    "acc_top5 = {}\n",
    "for model in model_labels:    \n",
    "    results = []\n",
    "    for qt in qts:\n",
    "        if model == 'fine-tuned resnet':\n",
    "            results.append(results_ft[qt]['top5'][0].tolist())\n",
    "        else:\n",
    "            results.append(results_pt[qt]['top5'][model][0].tolist())\n",
    "    acc_top5[model] = results\n",
    "\n",
    "# Add data to figure\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Bar(name=model, x=quartile_labels, y=acc_top5[model])\n",
    "        for model in model_labels\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Plot ########################################\n",
    "\n",
    "# Title and axis format\n",
    "fig.update_layout(\n",
    "    #title_text='',\n",
    "    title_x=0.5,\n",
    "    title_y=0.85,\n",
    "    xaxis_title=\"Monthly income (USD)\",\n",
    "    yaxis_title=\"Top 5 accuracy (%)\",\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    font=dict(\n",
    "        size=12,\n",
    "        color=\"black\"),\n",
    ")\n",
    "\n",
    "# Legend format\n",
    "fig.update_layout(legend=dict(\n",
    "    #yanchor=\"top\",\n",
    "    #y=0.5,\n",
    "    #xanchor=\"left\",\n",
    "    #x=1.01,\n",
    "    title_font_family=\"Times New Roman\",\n",
    "    font=dict(\n",
    "        size=12,\n",
    "        color=\"black\"),\n",
    "))\n",
    "\n",
    "# Overall layout\n",
    "fig.update_layout(template='seaborn')\n",
    "fig.update_layout(barmode='group')\n",
    "\n",
    "# Show\n",
    "fig.show()\n",
    "\n",
    "# Save\n",
    "filename = 'Figure6.pdf'\n",
    "save_path = os.path.join(\n",
    "    ROOT_DIR, ASSETS_FOLDER, PLOTS_FOLDER, filename)\n",
    "fig.write_image(save_path)\n",
    "print(f'Saved figure to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printout useful info for publication\n",
    "sum_ft = 0\n",
    "for qt in qts:\n",
    "    sum_pt = 0\n",
    "    count_pt = 0\n",
    "    for model, top5 in acc_top5.items():\n",
    "        if model == 'fine-tuned resnet':\n",
    "            sum_ft += top5[qt]\n",
    "        else:\n",
    "            sum_pt += top5[qt]\n",
    "            count_pt += 1\n",
    "    \n",
    "    print(f'average for all pre-trained models for quartile {qt}: {(sum_pt/count_pt):.2f}')\n",
    "    \n",
    "print(f'average for fine-tuned resnet across all quartiles: {(sum_ft/len(qts)):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18e2b0",
   "metadata": {},
   "source": [
    "# 3. Supplemental figure: train and score by quantile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a690a",
   "metadata": {},
   "source": [
    "## 3.1 Score pre-trained classifiers on quartile test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea5766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dollarstreet.run import validate_models\n",
    "\n",
    "model_names = [\n",
    "    'resnet',\n",
    "    'squeezenet',\n",
    "    'densenet',\n",
    "    'mobilenet',\n",
    "    'efficientnet',\n",
    "    'shufflenet',\n",
    "    'visionnet',\n",
    "]\n",
    "\n",
    "results_pt = {}\n",
    "for qt in qts:\n",
    "    description = (\n",
    "        f'Scoring all pre-trained models on {qt + 1}/{len(qts)} quantile '\n",
    "        'of test data.'\n",
    "    )\n",
    "    _, top1, top5 = validate_models(model_names=model_names,\n",
    "                                    dataloaders=qt_loaders[qt],\n",
    "                                    seed=training_seeds[0],\n",
    "                                    save_log=False,\n",
    "                                    description=description)\n",
    "    results_pt[qt] = {'top1': top1, 'top5': top5}\n",
    "    print(f'Finished scoring {qt + 1}/{len(qts)} quantile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96291b1",
   "metadata": {},
   "source": [
    "## 3.2 Score quartile-FT-resnets on quartile test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ae15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dollarstreet.run import validate_model\n",
    "\n",
    "# Load ft-resnet models trained on each quartile\n",
    "qt_models = {}\n",
    "for qt in qts:\n",
    "    filename = f'{os.path.splitext(QT_TRAIN_FILES[qt])[0]}_ftresnet.pickle'\n",
    "    model_save_path = os.path.join(\n",
    "            ROOT_DIR, ASSETS_FOLDER, MODELS_FOLDER, filename)\n",
    "\n",
    "    with open(model_save_path, 'rb') as handle:\n",
    "        qt_models[f'model_qt{qt}'] = pickle.load(handle)['resnet']\n",
    "\n",
    "results_ft = {qt:{} for qt in qts}\n",
    "for qt in qts:\n",
    "    top1 = {}\n",
    "    top5 = {}\n",
    "    for name, model in qt_models.items():\n",
    "        description = (\n",
    "            f'Scoring {name} fine-tuned model on {qt + 1}/{len(qts)} quantile '\n",
    "            'of test data.'\n",
    "        )\n",
    "        _, model_top1, model_top5 = validate_model(model=model,\n",
    "                                                   dataloaders=qt_loaders[qt],\n",
    "                                                   seed=training_seeds[0],\n",
    "                                                   save_log=False,\n",
    "                                                   description=description)\n",
    "        top1[name] = model_top1\n",
    "        top5[name] = model_top5\n",
    "        \n",
    "    results_ft[qt] = {'top1': top1, 'top5': top5}\n",
    "    print(f'Finished scoring {qt + 1}/{len(qts)} quantile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dc7fe6",
   "metadata": {},
   "source": [
    "## 3.3 Generate all quartile plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cea93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "for plot_qt in range(4):\n",
    "    quartile_ft_label = f'resnet fine-tuned with quartile{plot_qt}'\n",
    "    quartile_labels = ['$27-200', '$200-684', '$685-1,997', '$1,998-19,671']\n",
    "    model_labels = [\n",
    "        'resnet',\n",
    "        quartile_ft_label,\n",
    "    ]\n",
    "\n",
    "    # Get top 5 accuracy data per model per quartile\n",
    "    acc_top5 = {}\n",
    "    for model in model_labels:    \n",
    "        results = []\n",
    "        for qt in qts:\n",
    "            if model == quartile_ft_label:\n",
    "                results.append(results_ft[qt]['top5'][f'model_qt{plot_qt}'][0].tolist())\n",
    "            else:\n",
    "                results.append(results_pt[qt]['top5'][model][0].tolist())\n",
    "        acc_top5[model] = results\n",
    "\n",
    "    # Add data to figure\n",
    "    colors = {'resnet':'#2ca02c', quartile_ft_label:'#7f7f7f'}\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Bar(name=model, x=quartile_labels, y=acc_top5[model], marker_color=colors[model])\n",
    "            for model in model_labels\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Plot ########################################\n",
    "\n",
    "    # Title and axis format\n",
    "    fig.update_layout(\n",
    "        #title_text='',\n",
    "        title_x=0.5,\n",
    "        title_y=0.85,\n",
    "        xaxis_title=\"Monthly income (USD)\",\n",
    "        yaxis_title=\"Top 5 accuracy (%)\",\n",
    "        title_font_family=\"Times New Roman\",\n",
    "        font=dict(\n",
    "            size=12,\n",
    "            color=\"black\"),\n",
    "        yaxis_range=[0,83],\n",
    "    )\n",
    "\n",
    "    # Legend format\n",
    "    fig.update_layout(legend=dict(\n",
    "        #yanchor=\"top\",\n",
    "        #y=0.5,\n",
    "        #xanchor=\"left\",\n",
    "        #x=1.01,\n",
    "        title_font_family=\"Times New Roman\",\n",
    "        font=dict(\n",
    "            size=12,\n",
    "            color=\"black\"),\n",
    "    ))\n",
    "\n",
    "    # Overall layout\n",
    "    fig.update_layout(template='seaborn')\n",
    "    fig.update_layout(barmode='group')\n",
    "\n",
    "    # Show\n",
    "    fig.show()\n",
    "\n",
    "    # Save\n",
    "    filename = f'Supplemental_fig1_qt{plot_qt}.pdf'\n",
    "    save_path = os.path.join(\n",
    "        ROOT_DIR, ASSETS_FOLDER, PLOTS_FOLDER, filename)\n",
    "    fig.write_image(save_path)\n",
    "    print(f'Saved figure to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7df0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "musgIUtRnk9y"
   ],
   "name": "DollarStreet-Section6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sudnya-dollarstreet",
   "language": "python",
   "name": "sudnya-dollarstreet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
